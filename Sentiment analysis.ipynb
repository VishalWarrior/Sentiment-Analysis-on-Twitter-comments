{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc91118",
   "metadata": {},
   "source": [
    "# Build a clustering model on text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef0099",
   "metadata": {},
   "source": [
    "### Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e35132",
   "metadata": {},
   "source": [
    "##### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names\n",
    "columns = ['polarity', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "\n",
    "# Load the  dataset with specified encoding\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', names=columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30bea48",
   "metadata": {},
   "source": [
    "##### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b74f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f318b25e",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the tweet text by removing special characters, URLs, and unnecessary symbols.\n",
    "#Tokenize the text into individual words or subword units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57751a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Clean tweet text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\S+|[^A-Za-z0-9]+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d47694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization (using NLTK)\n",
    "nltk.download('punkt')\n",
    "df['tokens'] = df['cleaned_text'].apply(nltk.word_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['filtered_tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104a058",
   "metadata": {},
   "source": [
    "### Word Embeddings (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the tokenized text into dense vector representations (embeddings).\n",
    "#Use the Term Frequency-Inverse Document Frequency (TF-IDF) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe78d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "tfidf_matrix \n",
    "\n",
    "# Now tfidf_matrix contains the TF-IDF vectors for each tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4674e9",
   "metadata": {},
   "source": [
    "### Aggregating Text Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each tweet, compute the average or sum of the TF-IDF vectors to get a single vector representation for the entire tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average TF-IDF vector for each tweet\n",
    "average_tfidf_vector = tfidf_matrix.mean(axis=1)\n",
    "df['tfidf_vector'] = average_tfidf_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292712a",
   "metadata": {},
   "source": [
    "### Clustering (K-Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5670ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the number of clusters (K) based on domain knowledge or use techniques like the elbow method.\n",
    "#Train the K-Means model on the aggregated tweet vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# Assuming df['tfidf_vector'] contains the TF-IDF vectors\n",
    "tfidf_vectors = np.array(df['tfidf_vector'].tolist())  # Convert the column to a numpy array\n",
    "\n",
    "# Reshape the array to have two dimensions\n",
    "tfidf_vectors_2d = tfidf_vectors.reshape(-1, 1)  # Adjust the shape as per your data\n",
    "\n",
    "# Now, fit the KMeans model with the reshaped data\n",
    "kmeans.fit(tfidf_vectors_2d)\n",
    "\n",
    "# Assign cluster labels to each tweet\n",
    "df['cluster_label'] = kmeans.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the resulting clusters\n",
    "for cluster_id in range(5):\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    print(df[df['cluster_label'] == cluster_id]['text'].sample(5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b261ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sentiment analysis (example using rule-based approach)\n",
    "def get_sentiment(text):\n",
    "    # Implement your sentiment analysis logic here\n",
    "    # For simplicity, let's assume positive if the word \"happy\" appears, negative if \"sad\" appears\n",
    "    if \"happy\" in text.lower():\n",
    "        return \"Positive\"\n",
    "    elif \"sad\" in text.lower():\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df['sentiment'] = df['text'].apply(get_sentiment)\n",
    "\n",
    "\n",
    "# Print the sentiment for each tweet\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Tweet {index + 1}: {row['text']} - Sentiment: {row['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=list(sentiment_counts.keys()), y=list(sentiment_counts.values()))\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(\"Total Positive Tweets:\", positive_count)\n",
    "print(\"Total Negative Tweets:\", negative_count)\n",
    "print(\"Total Neutral Tweets:\", neutral_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4159a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
